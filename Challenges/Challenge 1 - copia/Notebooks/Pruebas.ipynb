{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_breast_cancer_data(file_path):\n",
    "    \"\"\"Loads the breast cancer Wisconsin dataset from a CSV file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: Data file not found at {file_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage with the specific path\n",
    "    file_path_example = r\"C:\\Users\\SABRINA PEREZ\\anaconda3\\Porgramacion-2\\data\\breast-cancer-wisconsin.data.csv\"\n",
    "    df = load_breast_cancer_data(file_path_example)\n",
    "    if df is not None:\n",
    "        print(\"Data loaded successfully (from example with specific path).\")\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing.py\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "def preprocess_module(df):\n",
    "    \"\"\"\n",
    "    Performs data exploration and preprocessing on the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the scaled features (X_scaled) and the target variable (y) if present,\n",
    "               otherwise just the scaled features (X_scaled, None).\n",
    "    \"\"\"\n",
    "    print(\"--- Data Exploration ---\")\n",
    "    print(\"Data Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nData Describe:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nData Value Counts for Each Column:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(df[col].value_counts())\n",
    "    print(\"\\nNull Value Counts:\")\n",
    "    print(df.isnull().sum())\n",
    "    # Add checks for other characters if needed (e.g., non-numeric in numeric columns)\n",
    "    print(\"\\n--- End of Data Exploration ---\")\n",
    "\n",
    "    print(\"\\n--- Data Preprocessing ---\")\n",
    "    df = df.drop(columns=[\"id\", \"Unnamed: 32\"], errors='ignore')\n",
    "    if 'diagnosis' in df.columns:\n",
    "        print(\"Encoding 'diagnosis' column.\")\n",
    "        df[\"diagnosis\"] = LabelEncoder().fit_transform(df[\"diagnosis\"])\n",
    "        X = df.drop(columns=[\"diagnosis\"])\n",
    "        y = df[\"diagnosis\"]\n",
    "    else:\n",
    "        print(\"Warning: 'diagnosis' column not found for label encoding.\")\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    print(\"Normalizing features.\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    print(\"--- End of Data Preprocessing ---\")\n",
    "\n",
    "    return X_scaled, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from module_load_data import load_breast_cancer_data\n",
    "    import os\n",
    "\n",
    "    # Assuming preprocessing.py is in the parent directory of the 'data' folder\n",
    "    file_path_example = os.path.join(os.path.dirname(__file__), 'breast-cancer-wisconsin.data.csv')\n",
    "\n",
    "    df = load_breast_cancer_data(file_path_example)\n",
    "    if df is not None:\n",
    "        X_scaled, y = preprocess_module(df)\n",
    "        print(\"\\nProcessed Data (first 5 rows of scaled features):\")\n",
    "        print(X_scaled[:5])\n",
    "        if y is not None:\n",
    "            print(\"\\nTarget variable (first 5 values):\")\n",
    "            print(y[:5])\n",
    "        else:\n",
    "            print(\"\\nNo target variable found after preprocessing.\")\n",
    "    else:\n",
    "        print(f\"Could not load data for preprocessing example from: {file_path_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_training.py\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime\n",
    "\n",
    "def train_model_module(X, y, model_name=\"random_forest\", test_size=0.2, random_state=42, n_estimators=100, learning_rate=0.1, max_depth=3, n_neighbors=5, solver='lbfgs', max_iter=100, kernel='rbf', C=1.0, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Trains a specified machine learning model with cross-validation and returns the trained model and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame or np.ndarray): Features.\n",
    "        y (pd.Series or np.ndarray): Target variable.\n",
    "        model_name (str): The name of the model to train ('random_forest', 'gradient_boosting', 'logistic_regression', 'knn', 'decision_tree', 'svm').\n",
    "        test_size (float): Proportion of the data to use for the test set.\n",
    "        random_state (int): Seed for random number generation.\n",
    "        n_estimators (int): Number of trees in the Random Forest or Gradient Boosting.\n",
    "        learning_rate (float): Learning rate for Gradient Boosting.\n",
    "        max_depth (int): Maximum depth of the Decision Tree or Gradient Boosting.\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        solver (str): Solver to use for Logistic Regression.\n",
    "        max_iter (int): Maximum number of iterations for Logistic Regression or SVM.\n",
    "        kernel (str): Kernel type for SVM.\n",
    "        C (float): Regularization parameter for Logistic Regression and SVM.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (trained model, X_test, y_test)\n",
    "    \"\"\"\n",
    "    print(f\"--- Model Training: {model_name} ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    if model_name == \"random_forest\":\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "        print(f\"Training RandomForest with {n_estimators} estimators.\")\n",
    "    elif model_name == \"gradient_boosting\":\n",
    "        model = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state)\n",
    "        print(f\"Training GradientBoosting with {n_estimators} estimators, learning rate={learning_rate}, max depth={max_depth}.\")\n",
    "    elif model_name == \"logistic_regression\":\n",
    "        model = LogisticRegression(solver=solver, max_iter=max_iter, random_state=random_state, C=C)\n",
    "        print(f\"Training Logistic Regression with solver='{solver}', max iterations={max_iter}, C={C}.\")\n",
    "    elif model_name == \"knn\":\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        print(f\"Training KNN with {n_neighbors} neighbors.\")\n",
    "    elif model_name == \"decision_tree\":\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "        print(f\"Training Decision Tree with max depth={max_depth}.\")\n",
    "    elif model_name == \"svm\":\n",
    "        model = SVC(kernel=kernel, C=C, max_iter=max_iter, random_state=random_state, probability=True) # probability=True for ROC curve\n",
    "        print(f\"Training SVM with kernel='{kernel}', C={C}, max iterations={max_iter}.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model trained.\")\n",
    "\n",
    "    print(f\"Performing {cv_folds}-fold stratified cross-validation.\")\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
    "    print(f\"Mean cross-validation accuracy: {cv_scores.mean():.2f}\")\n",
    "    print(f\"--- End of Model Training: {model_name} ---\")\n",
    "\n",
    "    return model, X_test, y_test\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from module_load_data import load_breast_cancer_data\n",
    "    from module_preprocessing import preprocess_module\n",
    "    import os\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation.py\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model_module(model, X_test, y_test, model_name=\"trained_model\"):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model and prints metrics and plots.\n",
    "\n",
    "    Args:\n",
    "        model: Trained machine learning model (must have predict and predict_proba methods).\n",
    "        X_test (pd.DataFrame or np.ndarray): Test features.\n",
    "        y_test (pd.Series or np.ndarray): True labels for the test set.\n",
    "        model_name (str): Name of the model for plot titles.\n",
    "    \"\"\"\n",
    "    print(f\"--- Model Evaluation: {model_name} ---\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.savefig(f\"confusion_matrix_{model_name}.png\")\n",
    "    plt.close()\n",
    "    print(f\"\\nConfusion matrix saved as confusion_matrix_{model_name}.png\")\n",
    "\n",
    "    # Calculate ROC Curve (only if the model has predict_proba)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot ROC Curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid()\n",
    "        plt.savefig(f\"roc_curve_{model_name}.png\")\n",
    "        plt.close()\n",
    "        print(f\"ROC curve saved as roc_curve_{model_name}.png\")\n",
    "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "    else:\n",
    "        print(f\"\\n{model_name} does not have predict_proba method, ROC curve cannot be calculated.\")\n",
    "\n",
    "    print(f\"--- End of Model Evaluation: {model_name} ---\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from module_load_data import load_breast_cancer_data\n",
    "    from module_preprocessing import preprocess_module\n",
    "    import os\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
